{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# fix imports\n",
                "import os\n",
                "import sys\n",
                "\n",
                "module_path = os.path.abspath(os.path.join(\"..\"))\n",
                "if module_path not in sys.path:\n",
                "    sys.path.append(module_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from notebooks.experiment_robust import load_robust_experiment\n",
                "from notebooks.experiment_torch import load_torchvision_experiment\n",
                "\n",
                "model, dl_train, dl_eval = load_robust_experiment(\"Salman2020Do_R50\", \"imagenet\", batch_size=128)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torchattacks\n",
                "\n",
                "attk_eps = 16 / 255\n",
                "attk_alpha = 8 / 255\n",
                "attk_steps = 5\n",
                "\n",
                "# torch_attack = torchattacks.FGSM(model, eps=attk_eps) # very fast; good\n",
                "# torch_attack = torchattacks.FFGSM(model, eps=attk_eps, alpha=attk_alpha)  # very fast; very good\n",
                "# torch_attack = torchattacks.DIFGSM(model, eps=attk_eps, alpha=attk_alpha, steps=attk_steps) # fast\n",
                "# torch_attack = torchattacks.RFGSM(model, eps=attk_eps, alpha=attk_alpha, steps=attk_steps) # fast; very good\n",
                "# torch_attack = torchattacks.BIM(model, eps=attk_eps, alpha=attk_alpha, steps=attk_steps) # fast\n",
                "# torch_attack = torchattacks.TIFGSM(model, eps=attk_eps, alpha=attk_alpha, steps=attk_steps) # fast\n",
                "# torch_attack = torchattacks.MIFGSM(model, eps=attk_eps, alpha=attl_alpha, steps=attk_steps)  # fast\n",
                "# torch_attack = torchattacks.NIFGSM(model, eps=attk_eps, alpha=attk_alpha, steps=attk_steps) # fast\n",
                "# torch_attack = torchattacks.PGDL2(model, eps=attk_eps, alpha=attk_alpha, steps=attk_steps) # fast\n",
                "# torch_attack = torchattacks.PGD(model) # fast\n",
                "# torch_attack = torchattacks.TPGD(model, eps=attk_eps, alpha=attk_alpha, steps=attk_steps) # fast\n",
                "torch_attack = torchattacks.UPGD(model, eps=attk_eps, alpha=attk_alpha, steps=attk_steps, loss=\"dlr\") # fast; very good\n",
                "# torch_attack = torchattacks.APGD(model, eps=attk_eps, steps=attk_steps, loss=\"dlr\") # fast; good\n",
                "# torch_attack = torchattacks.Jitter(model, eps=attk_eps, alpha=attk_alpha, steps=attk_steps) # fast; good\n",
                "# torch_attack = torchattacks.PIFGSM(model, max_epsilon=attk_eps, num_iter_set=attk_steps) # normal\n",
                "# torch_attack = torchattacks.PIFGSMPP(model, max_epsilon=attk_eps, num_iter_set=attk_steps) # normal\n",
                "# torch_attack = torchattacks.PGDRS(model, eps=attk_eps, alpha=attk_alpha, steps=attk_steps) # normal\n",
                "# torch_attack = torchattacks.EOTPGD(model, eps=attk_eps, alpha=attk_alpha, steps=attk_steps) # normal\n",
                "# torch_attack = torchattacks.PGDRSL2(model, eps=attk_eps, alpha=attk_alpha, steps=attk_steps) # slow\n",
                "# torch_attack = torchattacks.SINIFGSM(model, eps=attk_eps, alpha=attk_alpha, steps=attk_steps) # slow\n",
                "# torch_attack = torchattacks.VMIFGSM(model, eps=attk_eps, alpha=attk_alpha, steps=attk_steps) # very slow\n",
                "# torch_attack = torchattacks.EADEN(model, lr=attk_alpha, max_iterations=attk_steps) # very slow\n",
                "# torch_attack = torchattacks.VNIFGSM(model, eps=attk_eps, alpha=attk_alpha, steps=attk_steps) # very slow\n",
                "# torch_attack = torchattacks.APGDT(model, eps=attk_eps, steps=attk_steps) # very slow\n",
                "# torch_attack = torchattacks.SPSA(model, eps=attk_eps, lr=attk_alpha) # very slow\n",
                "# torch_attack = torchattacks.FAB(model, eps=attk_eps, steps=attk_steps) # very slow\n",
                "# torch_attack = torchattacks.CW(model, steps=attk_steps, lr=attk_alpha) # very slow\n",
                "# torch_attack = torchattacks.AutoAttack(model, eps=attk_eps) # super slow\n",
                "# torch_attack = torchattacks.Square(model, eps=attk_eps) # super slow\n",
                "# torch_attack = torchattacks.DeepFool(model, steps=attk_steps) # super slow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from ulib.utils.torch import extract_device\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "\n",
                "device = extract_device(model)\n",
                "# torch_attack = torchattacks.CW(model, steps=5, lr=attk_eps / 3)\n",
                "\n",
                "num_total = 0\n",
                "num_misclassified = 0\n",
                "\n",
                "for batch in tqdm(dl_eval):\n",
                "    with torch.device(device):\n",
                "        images, labels = batch\n",
                "        images = images.to(device)\n",
                "        labels = labels.to(device)\n",
                "\n",
                "        adv_images = torch_attack.forward(images, labels)\n",
                "\n",
                "        with torch.inference_mode():\n",
                "            pert = adv_images - images\n",
                "            pert = torch.clamp(pert, -attk_eps, attk_eps)\n",
                "            adv_input = torch.clamp(images + pert, 0, 1)\n",
                "            adv_preds = model(adv_input).argmax(dim=1)\n",
                "\n",
                "        num_total += labels.size(0)\n",
                "        num_misclassified += (adv_preds != labels).sum().item()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(num_misclassified / num_total)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "ulib",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
